counts <- c(18,17,15,20,10,20,25,13,12)
print(1)
q()
data("TitanicSurvival")
data("TitanicSurvival")
install.packages("titanic").
install.packages("titanic")
data("TitanicSurvival")
install.packages("titanic")
A = c(87, 55, 81, 42, 45, 54)
B = c(92, 72, 95, 55, 87, 66)
C = c(67, 82, 38, 55, 50, 82)
D = c(40, 88, 35, 39, 57, 80)
E = c(50, 88, 45, 50, 62, 90)
color = data.frame(A, B, C, D, E)
View(color)
cor_r = cor(color)
cor_r
eigen_v = eigen(cor_r)
eigen_v
round(eigen_v$values,3)
demo()
library(aod)
install.packages(aod)
install.packages("aod")
library(aod)
liarary(ggplot2)
library(ggplot2)
mydata <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")
# view the first few rows of the data
head(mydata)
# view the distribution of data
summary(mydata)
# view the structure of data
str(mydata)
sapply(mydata, sd)
# see the contingency table
xtabs(~admit+rank, data = mydata)
length(mydata)
length(mydata[0:])
getwd()
s
library(aod)
library(ggplot2)
# view the first few rows of the data
head(mydata)
summary(mydata)
source("C:/Users/kwbae/OneDrive - postech.ac.kr/workspace/R-study/Logistic_Regression.R", echo=TRUE)
std
# contingency table
xtabs(~admit+rank+gpa, data = mydata)
# contingency table
xtabs(~admit+rank, data = mydata)
# categorical variable
mydata$rank <- factor(mydata$rank)
mydata$rank
length(mydata$rank)
# logistic regression
mylogit <- glm(admit ~ gre+gpa+rank, data = mydata, family = "binomial")
mylogit
mydata
head(mydata)
head(mydata[:10])
head(mydata(:10))
head(mydata)
# linear regression
mylr <- lm(admit ~ gre+gpa+rank, data = mydata)
mylr
############### Import Library ###############
data <- read.csv("./dataset/SAS.csv")
df_reduced = data[, c("Cyber.Risk1", "Natural.Disaster2", "Month...Year.of.Settlement", "Loss.Amount...M.")]
df_reduced$`Month...Year.of.Settlement` <- as.character(df_reduced$`Month...Year.of.Settlement`)
colnames(df_reduced) <- c("cyber_risk", "nat_risk", "year_month", "loss")
df_reduced$year_month <- as.Date(df_reduced$year_month)
cyber.risk <- df_reduced[df_reduced$cyber_risk == 0, ]
nat.risk <- df_reduced[df_reduced$nat_risk == 1, ]
library(aod)
library(ggplot2)
############### Import Library ###############
data <- read.csv("./dataset/SAS.csv")
df_reduced = data[, c("Cyber.Risk1", "Natural.Disaster2", "Month...Year.of.Settlement", "Loss.Amount...M.")]
df_reduced$`Month...Year.of.Settlement` <- as.character(df_reduced$`Month...Year.of.Settlement`)
colnames(df_reduced) <- c("cyber_risk", "nat_risk", "year_month", "loss")
df_reduced$year_month <- as.Date(df_reduced$year_month)
cyber.risk <- df_reduced[df_reduced$cyber_risk == 0, ]
nat.risk <- df_reduced[df_reduced$nat_risk == 1, ]
cyber.nat <- df_reduced[df_reduced$cyber_risk == 1 & df_reduced$nat_risk == 1, ]
operational.risk <- df_reduced[df_reduced$cyber_risk == 0 & df_reduced$nat_risk == 0, ]
####
col(cyber.risk)
library(aod)
library(ggplot2)
############### Import Library ###############
data <- read.csv("./dataset/SAS.csv")
#################### Dataset Load ####################
data <- read.csv("./dataset/SAS.csv")
library(aod)
library(ggplot2)
library(MASS)
# install.packages("plotmo")
library(dplyr)
library(glmnet)
library(plotmo)
data <- read.csv("./dataset/SAS.csv")
sub.risk.employee <- ifelse(cyber$sub.risk == 'Employee Relations', 1, 0)
sub.risk.improper.business <- ifelse(cyber$sub.risk == 'Improper Business or Market Practices', 1, 0)
sub.risk.monitoring <- ifelse(cyber$sub.risk == 'Monitoring and Reporting', 1, 0)
sub.risk.product.flaws <- ifelse(cyber$sub.risk == 'Product Flaws', 1, 0)
sub.risk.selection <- ifelse(cyber$sub.risk == 'Selection, Sponsorship & Exposure', 1, 0)
sub.risk.customer <- ifelse(cyber$sub.risk == 'Customer Intake and Documentation', 1, 0)
sub.risk.suitability <- ifelse(cyber$sub.risk == 'Suitability, Disclosure & Fiduciary', 1, 0)
sub.risk.systems <- ifelse(cyber$sub.risk == 'Systems', 1, 0)
sub.risk.systems.security <- ifelse(cyber$sub.risk == 'Systems Security', 1, 0)
sub.risk.thefts <- ifelse(cyber$sub.risk == 'Theft and Fraud', 1, 0)
sub.risk.transaction <- ifelse(cyber$sub.risk == 'Transaction Capture, Execution & Maintenance', 1, 0)
sub.risk.unauthorized <- ifelse(cyber$sub.risk == 'Unauthorized Activity', 1, 0)
sub.risk.vendors <- ifelse(cyber$sub.risk == 'Vendors & Suppliers', 1, 0)
region.north.america <- ifelse(cyber$domicile.region == 'North America', 1, 0)
region.asia <- ifelse(cyber$domicile.region == 'Asia', 1, 0)
region.Other.americas <- ifelse(cyber$domicile.region == 'Other Americas', 1, 0)
region.africa <- ifelse(cyber$domicile.region == 'Africa', 1, 0)
region.other <- ifelse(cyber$domicile.region == 'Other', 1, 0)
region.europe <- ifelse(cyber$domicile.region == 'Europe', 1, 0)
library(aod)
library(ggplot2)
library(MASS)
# install.packages("plotmo")
library(dplyr)
library(glmnet)
library(plotmo)
data <- read.csv("./dataset/SAS.csv")
cyber.risk <- data[data$cyber_risk == 1, ]
length(cyber.risk$Reference.ID.Code)
cyber <- data.frame(cyber.risk$Loss.Amount...M.)
# cyber$current.loss <- as.numeric(cyber.risk$Current.Value.of.Loss...M.)
# cyber$basel.1 <- factor(cyber.risk$Basel.Business.Line...Level.1)
# cyber$basel.2 <- factor(cyber.risk$Basel.Business.Line...Level.2)
# cyber$business.unit <- factor(cyber.risk$Business.Unit)
# unique(cyber$business.unit)
# cyber$risk.category <- factor(cyber.risk$Event.Risk.Category)
cyber$sub.risk <- factor(cyber.risk$Sub.Risk.Category)
cyber <- data.frame(cyber.risk$Loss.Amount...M.)
cyber.risk <- data[data$cyber_risk == 1, ]
data <- read.csv("./dataset/SAS.csv")
data <- read.csv("./dataset/SAS.csv")
library(aod)
library(ggplot2)
library(MASS)
# install.packages("plotmo")
library(dplyr)
library(glmnet)
library(plotmo)
data <- read.csv("./dataset/SAS.csv")
cyber.risk <- data[data$cyber_risk == 1, ]
data <- read.csv("./dataset/SAS.csv")
library(aod)
library(ggplot2)
library(MASS)
library(dplyr)
library(glmnet)
library(plotmo)
require(mgcv)
data <- read.csv("./dataset/SAS.csv")
nat.risk <- data[data$nat_risk == 1, ]
install.libraries("forecast")
install.library("forecast")
install.packages("forecast")
# ===============================
# Import libraries and dataset
# ===============================
library("readxl") # read_excel
library("forecast")
data <- read_excel("./J12.xlsx")
~/Desktop/
getwd()
setwd('C:\Users\kwbae\OneDrive - postech.ac.kr\2024-1 POSTECH\06. 시계열분석\06. 과제 3')
setwd('C:/Users/kwbae/OneDrive - postech.ac.kr/2024-1 POSTECH/06. 시계열분석/06. 과제 3')
data <- read_excel("./J12.xlsx")
data <- read_excel("J12.xlsx")
data <- read_excel("./J12.xlsx")
data
data <- read_excel("./J12.xlsx")$서울사망자
data
# Assuming 'Month' is the column containing the dates and 'Deaths' is the column containing the number of deaths
ts_data <- ts(data, frequency = 12)
# Log transformation
log_ts_data <- log(ts_data)
# Plot original and log-transformed series
plot(ts_data, main = "Original Time Series")
plot(log_ts_data, main = "Log-Transformed Time Series")
# Check stationarity of log-transformed series
adf_test <- adf.test(log_ts_data)
print(adf_test)
install.packages("tseries")
install.packages("tseries")
# ===============================
# Import libraries and dataset
# ===============================
library("readxl") # read_excel
library("forecast")
library("tseries")
data <- read_excel("./J12.xlsx")$서울사망자
data
# Assuming 'Month' is the column containing the dates and 'Deaths' is the column containing the number of deaths
ts_data <- ts(data, frequency = 12)
# Log transformation
log_ts_data <- log(ts_data)
# Plot original and log-transformed series
plot(ts_data, main = "Original Time Series")
plot(log_ts_data, main = "Log-Transformed Time Series")
# Check stationarity of log-transformed series
adf_test <- adf.test(log_ts_data)
print(adf_test)
# Autocorrelation analysis
acf(log_ts_data)
pacf(log_ts_data)
# Model selection and fitting
# Example: ARIMA model
arima_model <- auto.arima(log_ts_data)
print(arima_model)
# Model evaluation
plot(forecast(arima_model))
# Autocorrelation analysis
acf(log_ts_data)
pacf(log_ts_data)
# ===============================
# Import libraries and dataset
# ===============================
library("readxl") # read_excel
library("forecast")
library("tseries")
data <- read_excel("./J12.xlsx")$서울사망자
data
# Assuming 'Month' is the column containing the dates and 'Deaths' is the column containing the number of deaths
ts_data <- ts(data, frequency = 12)
# Log transformation
log_ts_data <- log(ts_data)
# Plot original and log-transformed series
plot(ts_data, main = "Original Time Series")
plot(log_ts_data, main = "Log-Transformed Time Series")
# Check stationarity of log-transformed series
adf_test <- adf.test(log_ts_data)
print(adf_test)
# Autocorrelation analysis
acf(log_ts_data)
getwd()
setwd('C:/Users/kwbae/OneDrive - postech.ac.kr/2024-1 POSTECH/06. 시계열분석/07. 과제 4')
# ===============================
# Import libraries and dataset
# ===============================
library("readxl") # read_excel
library("forecast")
library("tseries")
data <- read_excel("./J12.xlsx")$서울사망자
data
# Assuming 'Month' is the column containing the dates and 'Deaths' is the column containing the number of deaths
arima_model <- arima(data, order = c(1, 0, 1))  # Example: ARIMA(1,0,1)
# Print model summary
summary(arima_model)
# Assuming 'Month' is the column containing the dates and 'Deaths' is the column containing the number of deaths
arima_model <- arima(data, order = c(1, 0, 0))  # Example: ARIMA(1,0,1)
# Print model summary
summary(arima_model)
# Ljung-Box test for residuals
residuals <- residuals(arima_model)
Ljung_Box_test <- Box.test(residuals, lag = 10, type = "Ljung-Box")
# Print Ljung-Box test results
print(Ljung_Box_test)
getwd()
setwd('C:/Users/kwbae/OneDrive - postech.ac.kr/2024-1 POSTECH/06. 시계열분석/07. 과제 4')
# ===============================
# Import libraries and dataset
# ===============================
library("readxl") # read_excel
library("forecast")
library("tseries")
data <- read_excel("./J12.xlsx")
data <- read_excel("./J08.xlsx")
data <- read_excel("./J08.xlsx")
# ===============================
# Import libraries and dataset
# ===============================
library("readxl") # read_excel
library("forecast")
library("tseries")
data <- read_excel("./J08.xlsx")
setwd('C:/Users/kwbae/OneDrive - postech.ac.kr/2024-1 POSTECH/06. 시계열분석/07. 과제 4')
data <- read_excel("./J08.xlsx")
data <- read_excel("./J08.xlsx")
data <- data$`Number of earthquakes per year magnitude 7.0 or greater. 1900-1998`
data
source("C:/Users/kwbae/OneDrive - postech.ac.kr/2024-1 POSTECH/06. 시계열분석/07. 과제 4/HW4-2.R", echo=TRUE)
data <- read_excel("./J08.xlsx")
colnames(data)
data <- data$...2
data
timeseries <- data[2:51]
timeseries
arima_model <- auto.arima(timeseries)
# Call auto.arima with ADF test
arima_model <- auto.arima(timeseries, test = "adf")
# Call auto.arima with ADF test
arima_model <- auto.arima(timeseries, test = "kpss")
arima_model <- arima(timeseries, order=c(1,0,0))
class(timeseries)
timeseries <- as.numeric(data[2:51])
arima_model <- arima(timeseries, order=c(1,0,0))
# Identify an appropriate ARIMA model using auto.arima
arima_model <- auto.arima(data)
arima_model <- arima(timeseries, order=c(1,0,0))
# Print the identified ARIMA model
print(arima_model)
# Estimate the parameters of the identified ARIMA model
fitted_model <- arima(data, order = arima_model$arma[c(1,6,2)])
# Estimate the parameters of the identified ARIMA model
fitted_model <- arima(timeseries, order = arima_model$arma[c(1,6,2)])
# Print model summary
summary(fitted_model)
# Diagnostic checking for residuals
plot(fitted_model$residuals, main = "Residuals of ARIMA Model")
acf(fitted_model$residuals, main = "ACF of Residuals")
pacf(fitted_model$residuals, main = "PACF of Residuals")
Box.test(fitted_model$residuals, lag = 10, type = "Ljung-Box")
acf(fitted_model$residuals, main = "ACF of Residuals")
pacf(fitted_model$residuals, main = "PACF of Residuals")
getwd()
setwd('C:/Users/kwbae/OneDrive - postech.ac.kr/2024-1 POSTECH/06. 시계열분석/07. 과제 4')
# ===============================
# Import libraries and dataset
# ===============================
library("readxl") # read_excel
library("forecast")
data <- read_excel("./J05.xlsx")
colnames(data)
data <- read_excel("./J05.xlsx", range=cell_rows(8:48), col_names=c("year", "dollar"))
data
colnames(data)
timeseries <- data$dollar
diff_timeseries <- diff(timeseries)
timeseries <- as.numeric(data$dollar)
timeseries <- as.numeric(data$dollar)
data$dollar
timeseries <- as.numeric(data$dollar[2:41])
diff_timeseries <- diff(timeseries)
# Plot ACF and PACF of the differenced series
par(mfrow = c(2, 1))
acf(diff_timeseries, main = "ACF of First Difference")
pacf(diff_timeseries, main = "PACF of First Difference")
# Plot ACF and PACF of the differenced series
par(mfrow = c(1, 1))
acf(diff_timeseries, main = "ACF of First Difference")
pacf(diff_timeseries, main = "PACF of First Difference")
# Estimate AR(1) model
ar1_model <- arima(diff_timeseries, order = c(1, 0, 0))
print(summary(ar1_model))
# Estimate MA(1) model
ma1_model <- arima(diff_timeseries, order = c(0, 0, 1))
print(summary(ma1_model))
# Estimate ARMA(1,1) model
arma11_model <- arima(diff_timeseries, order = c(1, 0, 1))
print(summary(arma11_model))
getwd()
setwd('C:/Users/kwbae/OneDrive - postech.ac.kr/2024-1 POSTECH/06. 시계열분석/07. 과제 4')
install.packages("astsa")
# ===============================
# Import libraries and dataset
# ===============================
library("readxl") # read_excel
library("forecast")
library("tseries")
library("astsa")
data <- read_excel("./J05.xlsx", range=cell_rows(8:48), col_names=c("year", "dollar"))
colnames(data)
timeseries <- as.numeric(data$dollar[2:41])
# Estimate ARMA(1,3) model
arma13_model <- arima(timeseries, order = c(1, 0, 3))
print(summary(arma13_model))
# One-step-ahead forecast
forecast_n <- predict(arma13_model, n.ahead = 1)
print(forecast_n$pred)
print(forecast_error_variance)
# Variance of forecast error
forecast_error_variance <- forecast_n$se^2
print(forecast_error_variance)
getwd()
setwd('C:/Users/kwbae/OneDrive - postech.ac.kr/2024-1 POSTECH/06. 시계열분석/07. 과제 4')
# ===============================
# Import libraries and dataset
# ===============================
library("readxl") # read_excel
library("forecast")
library("tseries")
library("astsa")
data <- read_excel("./J14.xlsx")
colnames(data)
data$`ma(2)`
timeseries <- as.numeric(data$`ma(2)`[2:length(data$`ma(2)`)])
ma2_model <- arima(timeseries[1:200], order = c(0, 0, 2))
print(summary(ma2_model))
# Obtain one-step-ahead forecasts for the period thereafter
forecast_values <- predict(ma2_model, n.ahead = length(timeseries) - 200)$pred
# Compare actual values to forecast values
actual_values <- timeseries[201:length(timeseries)]
forecast_errors <- actual_values - forecast_values
actual_values
forecast_errors
# Compute Root Mean Squared Error (RMSE)
RMSE <- sqrt(mean(forecast_errors^2))
# Compute Mean Absolute Deviation (MAD)
MAD <- mean(abs(forecast_errors))
# Compute Mean Absolute Percentage Error (MAPE)
MAPE <- mean(abs(forecast_errors / actual_values)) * 100
# Print forecast performance measures
cat("RMSE:", RMSE, "\n")
cat("MAD:", MAD, "\n")
cat("MAPE:", MAPE, "%\n")
